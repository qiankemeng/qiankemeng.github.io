/**
 * AI Paper Summarizer
 * ä½¿ç”¨å¤§æ¨¡å‹è¯¦ç»†æ€»ç»“è®ºæ–‡å†…å®¹
 */

import OpenAI from 'openai';
import { apiConfig, modelConfig, summarizeConfig } from './config.js';
import { retryWithBackoff } from './retry-utils.js';

// åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯
const openai = new OpenAI({
  apiKey: apiConfig.openai.apiKey,
  baseURL: apiConfig.openai.baseURL,
  organization: apiConfig.openai.organization,
  timeout: apiConfig.openai.timeout,
  maxRetries: apiConfig.openai.maxRetries,
});

/**
 * æ„å»ºæ€»ç»“prompt
 */
function buildSummarizePrompt(paper) {
  return `ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIç ”ç©¶è®ºæ–‡åˆ†æå¸ˆï¼Œä¸“æ³¨äºè§†é¢‘ç†è§£ã€å¤šæ¨¡æ€å¤§æ¨¡å‹å’ŒAI Agenté¢†åŸŸã€‚

è¯·ä»”ç»†é˜…è¯»ä»¥ä¸‹è®ºæ–‡ä¿¡æ¯ï¼Œå¹¶ç”¨**ä¸­æ–‡**æ’°å†™ä¸€ç¯‡è¯¦ç»†çš„è®ºæ–‡æ€»ç»“ã€‚

## è®ºæ–‡ä¿¡æ¯

**æ ‡é¢˜**: ${paper.title}

**ä½œè€…**: ${paper.authors.join(', ')}

**arXiv ID**: ${paper.arxivId}

**æ‘˜è¦**:
${paper.summary}

**åˆ†ç±»**: ${paper.categories.join(', ')}

${paper.filterReason ? `**ç­›é€‰ç†ç”±**: ${paper.filterReason}` : ''}

---

## æ€»ç»“è¦æ±‚

è¯·æŒ‰ç…§ä»¥ä¸‹ç»“æ„æ’°å†™æ€»ç»“ï¼ˆä½¿ç”¨Markdownæ ¼å¼ï¼‰ï¼š

### 1. æ ¸å¿ƒåˆ›æ–° (2-3æ®µ)
- è¿™ç¯‡è®ºæ–‡çš„ä¸»è¦åˆ›æ–°ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ
- ä¸ç°æœ‰æ–¹æ³•ç›¸æ¯”æœ‰ä»€ä¹ˆçªç ´ï¼Ÿ
- ä¸ºä»€ä¹ˆè¿™ä¸ªåˆ›æ–°å¾ˆé‡è¦ï¼Ÿ

### 2. æ–¹æ³•æ¦‚è¿° (3-4æ®µ)
- è®ºæ–‡æå‡ºçš„æ–¹æ³•æ˜¯ä»€ä¹ˆï¼Ÿ
- æŠ€æœ¯æ¶æ„æ˜¯æ€æ ·çš„ï¼Ÿ
- å…³é”®æŠ€æœ¯ç»†èŠ‚æœ‰å“ªäº›ï¼Ÿ
- å¦‚ä½•å®ç°çš„ï¼Ÿ

### 3. å®éªŒç»“æœ (2-3æ®µ)
- åœ¨å“ªäº›æ•°æ®é›†ä¸Šè¿›è¡Œäº†å®éªŒï¼Ÿ
- ä¸»è¦æ€§èƒ½æŒ‡æ ‡æ˜¯ä»€ä¹ˆï¼Ÿ
- ä¸baselineæ–¹æ³•å¯¹æ¯”å¦‚ä½•ï¼Ÿ
- æœ‰å“ªäº›å€¼å¾—å…³æ³¨çš„å®éªŒå‘ç°ï¼Ÿ

### 4. ä¸ªäººç‚¹è¯„ (1-2æ®µ)
- è¿™ç¯‡è®ºæ–‡çš„ä¼˜åŠ¿æ˜¯ä»€ä¹ˆï¼Ÿ
- å¯èƒ½çš„å±€é™æ€§æˆ–æ”¹è¿›æ–¹å‘ï¼Ÿ
- å¯¹è¯¥é¢†åŸŸçš„å½±å“å’Œæ„ä¹‰ï¼Ÿ
- å€¼å¾—å…³æ³¨çš„åŸå› ï¼Ÿ

---

## å†™ä½œè¦æ±‚

1. **è¯­è¨€**: ä½¿ç”¨æµç•…çš„ä¸­æ–‡å­¦æœ¯è¯­è¨€
2. **é•¿åº¦**: æ€»è®¡çº¦1000-1500å­—
3. **é£æ ¼**: ä¸“ä¸šä½†æ˜“æ‡‚ï¼Œé€‚åˆAIç ”ç©¶è€…é˜…è¯»
4. **é‡ç‚¹**: çªå‡ºæ ¸å¿ƒåˆ›æ–°å’Œå®ç”¨ä»·å€¼
5. **æ ¼å¼**: ä½¿ç”¨Markdownæ ¼å¼ï¼Œåˆç†ä½¿ç”¨æ ‡é¢˜ã€åˆ—è¡¨ã€åŠ ç²—ç­‰
6. **å®¢è§‚æ€§**: åŸºäºæ‘˜è¦å†…å®¹è¿›è¡Œåˆ†æï¼Œä¸è¦è¿‡åº¦æ¨æµ‹

è¯·ç›´æ¥è¾“å‡ºMarkdownæ ¼å¼çš„æ€»ç»“å†…å®¹ï¼Œä¸è¦åŒ…å«é¢å¤–çš„è¯´æ˜ã€‚`;
}

/**
 * ä½¿ç”¨AIæ€»ç»“å•ç¯‡è®ºæ–‡ï¼ˆå¸¦é‡è¯•ï¼‰
 */
export async function summarizePaper(paper) {
  console.log(`\nğŸ“ æ€»ç»“è®ºæ–‡: ${paper.title}...`);

  try {
    // ä½¿ç”¨é‡è¯•åŒ…è£…APIè°ƒç”¨
    const response = await retryWithBackoff(
      async () => {
        return await openai.chat.completions.create({
          model: modelConfig.summarize.model,
          messages: [
            {
              role: 'system',
              content: 'ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIç ”ç©¶è®ºæ–‡åˆ†æå¸ˆï¼Œæ“…é•¿ç”¨æ¸…æ™°æ˜“æ‡‚çš„ä¸­æ–‡æ€»ç»“è§†é¢‘ç†è§£ã€å¤šæ¨¡æ€å’ŒAI Agentç›¸å…³çš„è®ºæ–‡ã€‚ä½ çš„æ€»ç»“æ—¢è¦ä¿æŒå­¦æœ¯ä¸¥è°¨æ€§ï¼Œåˆè¦é€šä¿—æ˜“æ‡‚ã€‚'
            },
            {
              role: 'user',
              content: buildSummarizePrompt(paper)
            }
          ],
          temperature: modelConfig.summarize.temperature,
          max_tokens: modelConfig.summarize.maxTokens,
          top_p: modelConfig.summarize.topP,
          frequency_penalty: modelConfig.summarize.frequencyPenalty,
          presence_penalty: modelConfig.summarize.presencePenalty,
        });
      },
      {
        maxRetries: apiConfig.openai.maxRetries,
        baseDelay: 3000,  // 3ç§’åŸºç¡€å»¶è¿Ÿï¼ˆæ€»ç»“æ›´æ…¢ï¼‰
        maxDelay: 60000,  // æœ€å¤š60ç§’
        onRetry: (attempt, error) => {
          console.log(`ğŸ”„ æ€»ç»“APIé‡è¯•ä¸­ (${attempt + 1}/${apiConfig.openai.maxRetries})...`);
          console.log(`   é”™è¯¯: ${error.message}`);
        }
      }
    );

    const summary = response.choices[0].message.content;

    console.log(`âœ… æ€»ç»“å®Œæˆ (${summary.length} å­—ç¬¦)`);

    return {
      ...paper,
      summary_zh: summary,
      summary_generated_at: new Date().toISOString()
    };
  } catch (error) {
    console.error(`âŒ æ€»ç»“è®ºæ–‡ ${paper.arxivId} å¤±è´¥:`, error.message);
    throw error;
  }
}

/**
 * æ‰¹é‡æ€»ç»“è®ºæ–‡
 */
export async function summarizePapers(papers) {
  console.log(`\nğŸ¤– å¼€å§‹æ€»ç»“ ${papers.length} ç¯‡è®ºæ–‡ (ä½¿ç”¨ ${modelConfig.summarize.model})...\n`);

  const summarizedPapers = [];

  for (let i = 0; i < papers.length; i++) {
    console.log(`\n--- è¿›åº¦: ${i + 1}/${papers.length} ---`);

    try {
      const summarized = await summarizePaper(papers[i]);
      summarizedPapers.push(summarized);

      // é¿å…APIé™æµï¼Œè®ºæ–‡ä¹‹é—´å»¶è¿Ÿ2ç§’
      if (i < papers.length - 1) {
        console.log('â³ ç­‰å¾…2ç§’...');
        await new Promise(resolve => setTimeout(resolve, 2000));
      }
    } catch (error) {
      console.error(`è·³è¿‡è®ºæ–‡ ${papers[i].arxivId}: ${error.message}`);
      // ç»§ç»­å¤„ç†ä¸‹ä¸€ç¯‡
    }
  }

  console.log(`\nâœ… æ€»ç»“å®Œæˆ: ${summarizedPapers.length}/${papers.length} ç¯‡æˆåŠŸ\n`);

  return summarizedPapers;
}

/**
 * ç”Ÿæˆè‹±æ–‡ç‰ˆæœ¬çš„ç®€çŸ­æ€»ç»“
 */
export async function generateEnglishSummary(paper) {
  // æ£€æŸ¥é…ç½®æ˜¯å¦å¯ç”¨è‹±æ–‡æ€»ç»“
  if (!summarizeConfig.generateEnglish) {
    return paper;
  }

  console.log(`\nğŸŒ ç”Ÿæˆè‹±æ–‡ç‰ˆæœ¬: ${paper.arxivId}...`);

  const prompt = `Based on the following paper information, write a concise English summary (300-500 words):

**Title**: ${paper.title}
**Abstract**: ${paper.summary}

Please structure the summary as:
1. **Core Innovation** (1-2 paragraphs)
2. **Method Overview** (2-3 paragraphs)
3. **Key Results** (1-2 paragraphs)

Use clear, professional English suitable for AI researchers.`;

  try {
    // ä½¿ç”¨é‡è¯•åŒ…è£…APIè°ƒç”¨
    const response = await retryWithBackoff(
      async () => {
        return await openai.chat.completions.create({
          model: modelConfig.summarize.model,
          messages: [
            {
              role: 'system',
              content: 'You are an AI research paper analyst specializing in video understanding, multimodal models, and AI agents.'
            },
            {
              role: 'user',
              content: prompt
            }
          ],
          temperature: modelConfig.summarize.temperature,
          max_tokens: 2000,
          top_p: modelConfig.summarize.topP,
        });
      },
      {
        maxRetries: apiConfig.openai.maxRetries,
        baseDelay: 3000,
        maxDelay: 60000,
        onRetry: (attempt) => {
          console.log(`ğŸ”„ è‹±æ–‡æ€»ç»“APIé‡è¯•ä¸­ (${attempt + 1}/${apiConfig.openai.maxRetries})...`);
        }
      }
    );

    const summary_en = response.choices[0].message.content;
    console.log(`âœ… è‹±æ–‡æ€»ç»“å®Œæˆ`);

    return {
      ...paper,
      summary_en
    };
  } catch (error) {
    console.error(`âŒ ç”Ÿæˆè‹±æ–‡æ€»ç»“å¤±è´¥:`, error.message);
    // å¦‚æœè‹±æ–‡æ€»ç»“å¤±è´¥ï¼Œè¿”å›åŸè®ºæ–‡å¯¹è±¡
    return paper;
  }
}

/**
 * æµ‹è¯•å‡½æ•°
 */
export async function testSummarizer() {
  console.log('ğŸ§ª æµ‹è¯• AI Summarizer...\n');

  const mockPaper = {
    arxivId: '2404.12345',
    title: 'VideoLLaMA: A Multimodal Large Language Model for Video Understanding',
    summary: 'We present VideoLLaMA, a multimodal large language model designed specifically for video understanding tasks. Our model combines a video encoder with a large language model to enable comprehensive video analysis, including temporal reasoning, action recognition, and video question answering. Extensive experiments demonstrate state-of-the-art performance on multiple benchmarks.',
    authors: ['John Doe', 'Jane Smith'],
    categories: ['cs.CV', 'cs.AI'],
    filterReason: 'è¯¥è®ºæ–‡ç›´æ¥è§£å†³è§†é¢‘ç†è§£å’Œå¤šæ¨¡æ€å¤§æ¨¡å‹é—®é¢˜ï¼Œå…·æœ‰é‡è¦åˆ›æ–°'
  };

  try {
    const summarized = await summarizePaper(mockPaper);
    console.log('\nâœ… æµ‹è¯•æˆåŠŸ');
    console.log('\n--- ç”Ÿæˆçš„æ€»ç»“ ---');
    console.log(summarized.summary_zh);
  } catch (error) {
    console.error('\nâŒ æµ‹è¯•å¤±è´¥:', error.message);
  }
}

// å¦‚æœç›´æ¥è¿è¡Œæ­¤æ–‡ä»¶ï¼Œæ‰§è¡Œæµ‹è¯•
if (import.meta.url === `file://${process.argv[1]}`) {
  testSummarizer();
}
